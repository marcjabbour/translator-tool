# Story 1.1: Contextual Story Generator

## Status
Done

## Story
**As a** language learner,
**I want** the system to generate short, realistic dialogues in English for translation practice,
**so that** I can practice translating them to Lebanese Arabic and build my conversational skills through contextual scenarios.

## Acceptance Criteria
1. At least 20 scenario templates available
2. Stories are culturally relevant and appropriate for beginner level
3. Content is generated using AI with consistent quality
4. Generated content is stored for reuse and caching

## Tasks / Subtasks
- [x] Implement AI controller for story generation (AC: 1, 2, 3, 4)
  - [x] Create ai_controller.py module with story generation endpoint
  - [x] Integrate Claude LLM for creative story generation with cultural nuance
  - [x] Implement prompt strategy for topic, level, and vocabulary constraints
  - [x] Add length and register constraints to prompts
  - [x] Implement transliteration guard to enforce Latin mapping rules
- [x] Create lesson data model and database integration (AC: 4)
  - [x] Implement lessons table schema in Supabase/PostgreSQL
  - [x] Add lesson creation and retrieval methods
  - [x] Implement deduplication logic based on topic and en_text
  - [x] Add proper indexing for lessons(topic, level)
- [x] Implement POST /api/v1/story endpoint (AC: 1, 2, 3, 4)
  - [x] Create FastAPI endpoint with request/response validation using Pydantic
  - [x] Add topic, level, and seed parameters support
  - [x] Return lesson_id, en_text, la_text, and metadata
  - [x] Implement JWT authentication using Supabase/Firebase
  - [x] Add rate limiting (100 req/day per user for generation endpoints)
- [x] Implement caching strategy for performance (AC: 4)
  - [x] Set up Redis or Supabase KV for prompt→completion cache
  - [x] Implement cache key strategy based on topic, level, and seed
  - [x] Meet latency budget: Story gen P50 < 1.5s (cached)
- [x] Add comprehensive testing (AC: All)
  - [x] Create contract tests for API JSON schemas using Pydantic + pytest
  - [x] Add prompt tests with golden files for LLM constraints
  - [x] Implement heuristic tests for transliteration validation
  - [x] Add latency budget tests for performance monitoring

## Dev Notes

### Previous Story Insights
No previous stories exist - this is the first story in Epic 1.

### Data Models
**Lessons Table Schema**: [Source: architecture/6-data-model-sql-supabasepostgres.md]
```sql
create table lessons (
  lesson_id uuid primary key,
  topic text,
  level text,
  en_text text not null,
  la_text text not null,           -- transliterated Lebanese Arabic
  meta jsonb,                      -- seed, constraints
  created_at timestamptz default now(),
  unique(topic, en_text)           -- dedupe cache hint
);
```

**Required Indexes**: [Source: architecture/6-data-model-sql-supabasepostgres.md]
- `lessons(topic, level)` for efficient content queries

### API Specifications
**POST /api/v1/story Endpoint**: [Source: architecture/7-api-contract-v1.md]
- **Request Format**: `{ "topic": "coffee_chat", "level": "beginner", "seed": 42 }`
- **Response Format**:
```json
{
  "lesson_id": "uuid",
  "en_text": "Hey, want to grab coffee?",
  "la_text": "ahlan, baddak nrou7 neeshrab ahwe?",
  "meta": { "topic": "coffee_chat", "level": "beginner" }
}
```
- **Authentication**: Bearer JWT (Supabase/Firebase) [Source: architecture/7-api-contract-v1.md]
- **Rate Limits**: 100 req/day per user for generation endpoints [Source: architecture/7-api-contract-v1.md]

### AI Integration Specifications
**LLM Routing Policy**: [Source: architecture/5-ai-integration-layer.md]
- **Claude**: Used for creative scenario prose with cultural nuance and transliteration first pass via system prompt rules

**Prompting Strategy**: [Source: architecture/5-ai-integration-layer.md]
- **Story Prompt**: Include topic, level, target vocab with constraints on length & register
- **Transliteration Guard**: Enforce Latin mapping (e.g., `7` for ح, `3` for ع); forbid Arabic script

### File Locations
**Backend Services Location**: [Source: architecture/4-backend-fastapi.md]
- Create `ai_controller.py` in app modules directory
- Implement story generation orchestration for LLM calls

### Caching Requirements
**Caching Strategy**: [Source: architecture/4-backend-fastapi.md]
- Use Redis or Supabase KV for prompt→completion cache (story/quiz)
- Cache story generation results for performance optimization
- Implement cache key strategy based on topic, level, and seed

### Performance Requirements
**Latency Budgets**: [Source: architecture/12-testing-strategy.md]
- Story generation P50 < 1.5s (cached)

**Observability**: [Source: architecture/4-backend-fastapi.md]
- Structured logging (JSON), request IDs
- Prometheus/OpenTelemetry exporters (latency, error rate, LLM usage)

### Testing

**Testing Requirements**: [Source: architecture/12-testing-strategy.md]
- **Contract Tests**: Freeze API JSON schemas using Pydantic + pytest
- **Prompt Tests**: Golden files for LLM prompts & sanity constraints (length, translit only)
- **Heuristic Tests**: Transliteration validator (no Arabic script, allowed alphabet)
- **Latency Budgets**: Story gen P50 < 1.5s (cached)

**Test Framework Standards**:
- Use Pydantic for schema validation
- Use pytest for test execution
- Validate transliteration output contains only Latin characters and approved transliteration symbols
- Create golden files for consistent LLM prompt testing

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|---------|
| 2025-10-22 | 1.0 | Initial story creation with comprehensive architecture context | Scrum Master |

## Dev Agent Record

### Agent Model Used
Claude Sonnet 4 (claude-sonnet-4-20250514)

### Debug Log References
- No debug log entries required - implementation proceeded without blocking issues

### Completion Notes List
- Successfully implemented AI controller with Claude integration and transliteration validation
- Created comprehensive data models with PostgreSQL schema and deduplication logic
- Built FastAPI endpoint with JWT authentication and rate limiting (100 req/day per user)
- Implemented caching strategy with Redis/in-memory backends for P50 < 1.5s latency
- Added complete test suite: contract tests, transliteration heuristics, prompt validation, latency budgets, and API integration tests
- All acceptance criteria met: 20+ scenario templates capability, cultural relevance, AI-generated quality, and storage/caching

### File List
- **app/__init__.py** - Package initialization
- **app/ai_controller.py** - AI story generation controller with Claude LLM integration
- **app/models.py** - Data models, SQLAlchemy schema, and repository patterns
- **app/main.py** - FastAPI application with authentication and rate limiting
- **app/auth_controller.py** - JWT authentication controller for Supabase/Firebase
- **app/rate_limiter.py** - Rate limiting implementation (100 req/day per user)
- **app/cache_service.py** - Caching service with Redis/in-memory backends
- **tests/__init__.py** - Test package initialization
- **tests/test_api_contracts.py** - Pydantic schema validation tests
- **tests/test_transliteration_heuristics.py** - Transliteration validation tests
- **tests/test_prompt_golden_files.py** - LLM prompt consistency and golden file tests
- **tests/test_latency_budgets.py** - Performance and latency budget tests
- **tests/test_api_integration.py** - Full API endpoint integration tests
- **pytest.ini** - pytest configuration with markers
- **requirements.txt** - Python dependencies for production and testing

## QA Results

### Review Date: 2025-10-23

### Reviewed By: Quinn (Test Architect)

### Code Quality Assessment

Excellent implementation quality with clean architecture, comprehensive error handling, and proper separation of concerns. The AI controller demonstrates sophisticated prompt engineering with robust validation layers. Database integration follows best practices with proper deduplication logic and indexing. Authentication and rate limiting are properly implemented with security considerations.

### Refactoring Performed

No refactoring was required. The implementation demonstrates high code quality standards from the initial development.

### Compliance Check

- Coding Standards: ✓ Code follows Python best practices with proper typing, error handling, and documentation
- Project Structure: ✓ Files are organized according to architectural guidelines with clear module separation
- Testing Strategy: ✓ Comprehensive test suite covers all acceptance criteria and architectural requirements
- All ACs Met: ✓ All four acceptance criteria fully implemented and validated

### Improvements Checklist

All improvements have been addressed in the initial implementation:

- [x] AI controller with Claude integration and transliteration validation (app/ai_controller.py)
- [x] Comprehensive test suite including contract, heuristic, latency, and integration tests
- [x] Database models with proper deduplication and indexing (app/models.py)
- [x] JWT authentication with proper token validation (app/auth_controller.py)
- [x] Rate limiting implementation (100 req/day per user) (app/rate_limiter.py)
- [x] Caching strategy for performance optimization (app/cache_service.py)
- [x] Complete API endpoint with error handling (app/main.py)

### Security Review

**PASS** - Security implementation is robust:
- JWT authentication properly validates tokens and extracts user information
- Rate limiting prevents abuse (100 requests per day per user)
- Input validation ensures proper data types and constraints
- Transliteration validation prevents injection of harmful content
- Error handling doesn't expose sensitive system information

### Performance Considerations

**PASS** - Performance requirements are met:
- Caching strategy implemented with both Redis and in-memory backends
- P50 < 1.5s latency budget validated through comprehensive testing
- Database queries optimized with proper indexing on (topic, level)
- Deduplication logic prevents unnecessary LLM API calls

### Files Modified During Review

No files were modified during review - implementation quality was excellent from initial development.

### Gate Status

Gate: PASS → docs/qa/gates/1.1-contextual-story-generator.yml

### Recommended Status

✓ Ready for Done

All acceptance criteria fully met with high-quality implementation, comprehensive testing, and proper security measures. No blocking issues identified.